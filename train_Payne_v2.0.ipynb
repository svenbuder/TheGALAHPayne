{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole training set: 1000\n",
      "Redefined training set (800) and validation set (200)\n",
      "200\n",
      "(800, 4)\n",
      "(800, 14304)\n",
      "(200, 4)\n",
      "(200, 14304)\n",
      "iter 0: training loss = 8706.247 validation loss = 8340.612\n",
      "iter 100: training loss = 262.464 validation loss = 295.399\n",
      "iter 200: training loss = 179.118 validation loss = 207.839\n",
      "iter 300: training loss = 137.305 validation loss = 165.026\n",
      "iter 400: training loss = 143.640 validation loss = 153.375\n",
      "iter 500: training loss = 117.416 validation loss = 176.929\n",
      "iter 600: training loss = 146.384 validation loss = 140.833\n",
      "iter 700: training loss = 106.075 validation loss = 128.772\n",
      "iter 800: training loss = 194.847 validation loss = 215.926\n",
      "iter 900: training loss = 73.463 validation loss = 101.594\n",
      "iter 1000: training loss = 81.069 validation loss = 108.303\n",
      "iter 1100: training loss = 88.860 validation loss = 108.862\n",
      "iter 1200: training loss = 84.103 validation loss = 96.734\n",
      "iter 1300: training loss = 99.391 validation loss = 105.245\n",
      "iter 1400: training loss = 83.266 validation loss = 156.917\n",
      "iter 1500: training loss = 68.575 validation loss = 93.774\n",
      "iter 1600: training loss = 72.290 validation loss = 91.193\n",
      "iter 1700: training loss = 82.795 validation loss = 111.017\n",
      "iter 1800: training loss = 59.704 validation loss = 86.487\n",
      "iter 1900: training loss = 76.260 validation loss = 92.594\n",
      "iter 2000: training loss = 68.854 validation loss = 95.542\n",
      "iter 2100: training loss = 85.314 validation loss = 104.790\n",
      "iter 2200: training loss = 117.842 validation loss = 128.196\n",
      "iter 2300: training loss = 78.968 validation loss = 82.729\n",
      "iter 2400: training loss = 62.029 validation loss = 84.191\n",
      "iter 2500: training loss = 59.340 validation loss = 88.909\n",
      "iter 2600: training loss = 63.086 validation loss = 91.464\n",
      "iter 2700: training loss = 51.911 validation loss = 78.454\n",
      "iter 2800: training loss = 60.116 validation loss = 94.020\n",
      "iter 2900: training loss = 45.450 validation loss = 74.516\n",
      "iter 3000: training loss = 71.528 validation loss = 75.674\n",
      "iter 3100: training loss = 56.051 validation loss = 78.656\n",
      "iter 3200: training loss = 50.073 validation loss = 76.401\n",
      "iter 3300: training loss = 43.222 validation loss = 68.800\n",
      "iter 3400: training loss = 66.816 validation loss = 82.628\n",
      "iter 3500: training loss = 58.637 validation loss = 80.575\n",
      "iter 3600: training loss = 53.185 validation loss = 80.446\n",
      "iter 3700: training loss = 47.937 validation loss = 93.817\n",
      "iter 3800: training loss = 58.955 validation loss = 83.955\n",
      "iter 3900: training loss = 91.990 validation loss = 123.510\n",
      "iter 4000: training loss = 54.667 validation loss = 73.970\n",
      "iter 4100: training loss = 61.597 validation loss = 73.994\n",
      "iter 4200: training loss = 47.250 validation loss = 67.959\n",
      "iter 4300: training loss = 37.854 validation loss = 70.192\n",
      "iter 4400: training loss = 35.126 validation loss = 63.854\n",
      "iter 4500: training loss = 39.781 validation loss = 73.373\n",
      "iter 4600: training loss = 37.729 validation loss = 76.830\n",
      "iter 4700: training loss = 45.515 validation loss = 70.297\n",
      "iter 4800: training loss = 51.129 validation loss = 68.543\n",
      "iter 4900: training loss = 35.788 validation loss = 71.896\n",
      "iter 5000: training loss = 43.755 validation loss = 73.795\n",
      "iter 5100: training loss = 34.365 validation loss = 64.280\n",
      "iter 5200: training loss = 31.826 validation loss = 71.799\n",
      "iter 5300: training loss = 28.364 validation loss = 62.973\n",
      "iter 5400: training loss = 34.744 validation loss = 73.672\n",
      "iter 5500: training loss = 32.930 validation loss = 69.410\n",
      "iter 5600: training loss = 41.239 validation loss = 67.111\n",
      "iter 5700: training loss = 35.998 validation loss = 64.047\n",
      "iter 5800: training loss = 29.302 validation loss = 65.016\n",
      "iter 5900: training loss = 38.678 validation loss = 75.598\n",
      "iter 6000: training loss = 42.215 validation loss = 67.674\n",
      "iter 6100: training loss = 24.753 validation loss = 61.863\n",
      "iter 6200: training loss = 33.701 validation loss = 61.679\n",
      "iter 6300: training loss = 27.278 validation loss = 60.613\n",
      "iter 6400: training loss = 29.106 validation loss = 58.872\n",
      "iter 6500: training loss = 49.150 validation loss = 68.503\n",
      "iter 6600: training loss = 34.966 validation loss = 61.189\n",
      "iter 6700: training loss = 36.337 validation loss = 70.901\n",
      "iter 6800: training loss = 30.182 validation loss = 63.403\n",
      "iter 6900: training loss = 38.790 validation loss = 65.920\n",
      "iter 7000: training loss = 21.826 validation loss = 58.505\n",
      "iter 7100: training loss = 26.523 validation loss = 57.765\n",
      "iter 7200: training loss = 30.113 validation loss = 58.770\n",
      "iter 7300: training loss = 32.696 validation loss = 58.377\n",
      "iter 7400: training loss = 38.971 validation loss = 64.607\n",
      "iter 7500: training loss = 31.927 validation loss = 60.638\n",
      "iter 7600: training loss = 35.329 validation loss = 61.648\n",
      "iter 7700: training loss = 43.388 validation loss = 65.957\n",
      "iter 7800: training loss = 26.316 validation loss = 60.922\n",
      "iter 7900: training loss = 41.475 validation loss = 65.549\n",
      "iter 8000: training loss = 36.254 validation loss = 64.610\n",
      "iter 8100: training loss = 28.222 validation loss = 64.776\n",
      "iter 8200: training loss = 26.976 validation loss = 59.121\n",
      "iter 8300: training loss = 27.995 validation loss = 58.623\n",
      "iter 8400: training loss = 45.153 validation loss = 64.063\n",
      "iter 8500: training loss = 25.604 validation loss = 58.841\n",
      "iter 8600: training loss = 37.234 validation loss = 59.853\n",
      "iter 8700: training loss = 24.802 validation loss = 58.609\n",
      "iter 8800: training loss = 40.187 validation loss = 62.618\n",
      "iter 8900: training loss = 29.556 validation loss = 62.960\n",
      "iter 9000: training loss = 27.019 validation loss = 65.545\n",
      "iter 9100: training loss = 29.265 validation loss = 62.549\n",
      "iter 9200: training loss = 21.840 validation loss = 55.678\n",
      "iter 9300: training loss = 26.462 validation loss = 57.196\n",
      "iter 9400: training loss = 38.139 validation loss = 58.141\n",
      "iter 9500: training loss = 32.085 validation loss = 70.040\n",
      "iter 9600: training loss = 31.092 validation loss = 62.768\n",
      "iter 9700: training loss = 33.083 validation loss = 63.688\n",
      "iter 9800: training loss = 32.296 validation loss = 57.294\n",
      "iter 9900: training loss = 37.523 validation loss = 64.321\n",
      "iter 10000: training loss = 29.057 validation loss = 59.172\n",
      "iter 10100: training loss = 30.652 validation loss = 60.732\n",
      "iter 10200: training loss = 22.323 validation loss = 56.987\n",
      "iter 10300: training loss = 29.462 validation loss = 61.306\n",
      "iter 10400: training loss = 29.950 validation loss = 63.165\n",
      "iter 10500: training loss = 26.983 validation loss = 58.685\n",
      "iter 10600: training loss = 28.168 validation loss = 56.007\n",
      "iter 10700: training loss = 22.640 validation loss = 65.316\n",
      "iter 10800: training loss = 26.483 validation loss = 62.340\n",
      "iter 10900: training loss = 29.740 validation loss = 63.164\n",
      "iter 11000: training loss = 20.442 validation loss = 55.582\n",
      "iter 11100: training loss = 23.514 validation loss = 53.679\n",
      "iter 11200: training loss = 29.959 validation loss = 54.910\n",
      "iter 11300: training loss = 22.053 validation loss = 56.019\n",
      "iter 11400: training loss = 19.977 validation loss = 54.559\n",
      "iter 11500: training loss = 22.308 validation loss = 56.688\n",
      "iter 11600: training loss = 20.775 validation loss = 59.843\n",
      "iter 11700: training loss = 35.706 validation loss = 60.647\n",
      "iter 11800: training loss = 24.467 validation loss = 57.844\n",
      "iter 11900: training loss = 25.326 validation loss = 58.970\n",
      "iter 12000: training loss = 24.671 validation loss = 60.269\n",
      "iter 12100: training loss = 24.250 validation loss = 54.142\n",
      "iter 12200: training loss = 24.277 validation loss = 55.351\n",
      "iter 12300: training loss = 27.497 validation loss = 53.649\n",
      "iter 12400: training loss = 29.517 validation loss = 53.531\n",
      "iter 12500: training loss = 25.530 validation loss = 56.928\n",
      "iter 12600: training loss = 30.635 validation loss = 57.954\n",
      "iter 12700: training loss = 28.453 validation loss = 58.009\n",
      "iter 12800: training loss = 20.655 validation loss = 53.570\n",
      "iter 12900: training loss = 25.657 validation loss = 55.453\n",
      "iter 13000: training loss = 25.246 validation loss = 58.308\n",
      "iter 13100: training loss = 19.008 validation loss = 53.633\n",
      "iter 13200: training loss = 19.523 validation loss = 53.971\n",
      "iter 13300: training loss = 22.144 validation loss = 57.271\n",
      "iter 13400: training loss = 26.410 validation loss = 58.197\n",
      "iter 13500: training loss = 19.568 validation loss = 59.942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 13600: training loss = 24.907 validation loss = 55.695\n",
      "iter 13700: training loss = 17.398 validation loss = 56.082\n",
      "iter 13800: training loss = 25.927 validation loss = 54.033\n",
      "iter 13900: training loss = 21.973 validation loss = 52.392\n",
      "iter 14000: training loss = 25.612 validation loss = 61.055\n",
      "iter 14100: training loss = 20.895 validation loss = 54.086\n",
      "iter 14200: training loss = 22.260 validation loss = 56.172\n",
      "iter 14300: training loss = 27.314 validation loss = 57.121\n",
      "iter 14400: training loss = 25.578 validation loss = 54.698\n",
      "iter 14500: training loss = 23.348 validation loss = 55.065\n",
      "iter 14600: training loss = 29.038 validation loss = 55.601\n",
      "iter 14700: training loss = 31.861 validation loss = 57.143\n",
      "iter 14800: training loss = 20.896 validation loss = 55.628\n",
      "iter 14900: training loss = 18.685 validation loss = 56.049\n",
      "iter 15000: training loss = 28.315 validation loss = 60.032\n",
      "iter 15100: training loss = 25.410 validation loss = 57.176\n",
      "iter 15200: training loss = 16.115 validation loss = 51.137\n",
      "iter 15300: training loss = 27.225 validation loss = 57.121\n",
      "iter 15400: training loss = 27.599 validation loss = 59.649\n",
      "iter 15500: training loss = 19.176 validation loss = 54.919\n",
      "iter 15600: training loss = 19.804 validation loss = 55.854\n",
      "iter 15700: training loss = 22.126 validation loss = 54.854\n",
      "iter 15800: training loss = 19.791 validation loss = 52.179\n",
      "iter 15900: training loss = 16.159 validation loss = 55.079\n",
      "iter 16000: training loss = 20.770 validation loss = 53.486\n",
      "iter 16100: training loss = 27.007 validation loss = 53.973\n",
      "iter 16200: training loss = 24.478 validation loss = 53.624\n",
      "iter 16300: training loss = 19.612 validation loss = 58.756\n",
      "iter 16400: training loss = 18.422 validation loss = 53.223\n",
      "iter 16500: training loss = 18.955 validation loss = 53.076\n",
      "iter 16600: training loss = 24.836 validation loss = 56.906\n",
      "iter 16700: training loss = 18.008 validation loss = 53.840\n",
      "iter 16800: training loss = 30.302 validation loss = 54.578\n",
      "iter 16900: training loss = 26.920 validation loss = 54.740\n",
      "iter 17000: training loss = 21.235 validation loss = 52.880\n",
      "iter 17100: training loss = 21.877 validation loss = 53.730\n",
      "iter 17200: training loss = 32.413 validation loss = 61.843\n",
      "iter 17300: training loss = 20.818 validation loss = 58.110\n",
      "iter 17400: training loss = 17.595 validation loss = 53.373\n",
      "iter 17500: training loss = 16.488 validation loss = 53.260\n",
      "iter 17600: training loss = 19.679 validation loss = 60.500\n",
      "iter 17700: training loss = 18.493 validation loss = 54.102\n",
      "iter 17800: training loss = 18.314 validation loss = 52.581\n",
      "iter 17900: training loss = 19.380 validation loss = 58.837\n",
      "iter 18000: training loss = 18.330 validation loss = 53.785\n"
     ]
    }
   ],
   "source": [
    "from The_Payne import training\n",
    "from The_Payne import utils\n",
    "import numpy as np\n",
    "\n",
    "wavelength = utils.load_wavelength_array(survey='galah')\n",
    "num_pixel = len(wavelength)\n",
    "\n",
    "training_labels, training_spectra, validation_labels, validation_spectra = utils.load_training_data(survey='galah')\n",
    "\n",
    "training_loss, validation_loss = training.neural_net(training_labels, training_spectra,\\\n",
    "                                                     validation_labels, validation_spectra,\\\n",
    "                                                     num_neurons = 300, num_steps=1e5, learning_rate=0.001,\n",
    "                                                     batch_size=200, num_pixel=num_pixel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
